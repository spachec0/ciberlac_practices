# LLM04- Data and Model Poisoning

Data poisoning occurs when pre-training, fine-tuning, or embedding data is manipulated to introduce vulnerabilities, backdoors, or biases. This manipulation can compromise model security, performance, or ethical behavior, leading to harmful outputs or impaired capabilities. Common risks include degraded model performance, biased or toxic content, and exploitation of downstream systems.

The application allows users to ask questions based on the OWASP LLM Top 10 document. However, the source document LLM is referring is publicly accessible and editable. A malicious actor can modify this document to inject misleading or harmful content, influencing the chatbot's responses.

## Challenge Objective
Participants must identify how the model's behavior has been poisoned by tampered data and potentially exploit it to modify LLM Top 10 entries such that it replaces LLM01. 

Application URL: http://127.0.0.1:5004

**Hint:** Identify the source


